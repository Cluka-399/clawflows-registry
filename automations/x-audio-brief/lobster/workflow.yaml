# Lobster workflow: x-audio-brief
# Search X/Twitter for a topic via Brave Search, collect posts and discussion,
# produce a structured summary, and optionally convert to audio via ElevenLabs TTS.
#
# Usage:
#   lobster run --file workflow.yaml --args-json '{"topic":"OpenAI","skip_tts":"true"}'
#
# Requires: curl, jq (at /home/node/bin/jq)
# Env: BRAVE_API_KEY, ELEVENLABS_API_KEY (for TTS)
#
# Note: Brave Search returns a mix of X profile pages, archived tweets (archive.is),
# and news articles discussing X/Twitter activity. The workflow extracts and combines
# all sources to produce a comprehensive briefing.

name: x-audio-brief
description: Search X/Twitter for a topic, summarize what people are saying, and deliver as audio briefing

env:
  PATH: "/home/node/bin:/usr/local/bin:/usr/bin:/bin"

args:
  topic:
    description: "What to search for on X/Twitter"
  days:
    description: "How far back to search (1-30)"
    default: "1"
  max_tweets:
    description: "Maximum posts/mentions to include in summary"
    default: "15"
  voice:
    description: "TTS voice (adam or rachel)"
    default: "adam"
  skip_tts:
    description: "Skip TTS generation (set to false to actually generate audio)"
    default: "true"
  output_dir:
    description: "Directory for output files"
    default: "/tmp/x-audio-brief"

steps:
  - id: setup
    command: |
      mkdir -p "${output_dir}"
      echo '{"status":"ready"}'

  - id: search-x-posts
    command: |
      # Determine freshness based on days arg
      freshness="pd"
      days_num="${days}"
      if [ "$days_num" -gt 7 ] 2>/dev/null; then
        freshness="pm"
      elif [ "$days_num" -gt 1 ] 2>/dev/null; then
        freshness="pw"
      fi

      # Query 1: Recent X/Twitter content (with freshness)
      curl -sf "https://api.search.brave.com/res/v1/web/search" \
        -H "X-Subscription-Token: ${BRAVE_API_KEY}" \
        -H "Accept: application/json" \
        --data-urlencode "q=${topic} x.com" \
        --data-urlencode "count=20" \
        --data-urlencode "freshness=$freshness" \
        -G \
        -o "${output_dir}/brave_q1.json" 2>/dev/null || echo '{"web":{"results":[]}}' > "${output_dir}/brave_q1.json"

      # Query 2: News + discussion about topic on X/Twitter
      curl -sf "https://api.search.brave.com/res/v1/web/search" \
        -H "X-Subscription-Token: ${BRAVE_API_KEY}" \
        -H "Accept: application/json" \
        --data-urlencode "q=${topic} twitter reactions discussion" \
        --data-urlencode "count=10" \
        --data-urlencode "freshness=$freshness" \
        -G \
        -o "${output_dir}/brave_q2.json" 2>/dev/null || echo '{"web":{"results":[]}}' > "${output_dir}/brave_q2.json"

      # Parse results into unified post format
      # Handles: x.com profile pages, archive.is/ph cached tweets, news articles
      cat > /tmp/xab_parse.jq << 'JQEOF'
      [.web.results // [] | .[] |
        # Detect archived X posts (archive.is/ph with "on X:" in title)
        if ((.url | test("archive\\.(is|ph|org)")) and (.title | test("on X:"; "i"))) then
          (.title | capture("^(?<author>[^@]+?)\\s+on X:\\s*\"?(?<text>.+?)\"?$") // {author: "unknown", text: (.title // "")}) as $parsed |
          {
            author: ($parsed.author | gsub("^\\s+|\\s+$"; "")),
            content: ($parsed.text // .description // ""),
            title: .title,
            url: .url,
            date: (.age // .page_age // "recent"),
            source: "x_post"
          }
        # Detect x.com/twitter.com URLs
        elif (.url | test("(x\\.com|twitter\\.com)")) then
          (.url | capture("(?:x|twitter)\\.com/(?<handle>[^/?]+)") // {handle: "unknown"}) as $p |
          {
            author: $p.handle,
            content: (.description // .title // ""),
            title: (.title // ""),
            url: .url,
            date: (.age // .page_age // "recent"),
            source: (if (.url | test("/status/")) then "x_post" else "x_profile" end)
          }
        # News/other articles
        else
          {
            author: (.meta_url.hostname // .url | split("/") | .[2] // "unknown"),
            content: (.description // .title // ""),
            title: (.title // ""),
            url: .url,
            date: (.age // .page_age // "recent"),
            source: "news"
          }
        end
      ]
      JQEOF

      jq -f /tmp/xab_parse.jq "${output_dir}/brave_q1.json" > "${output_dir}/posts_q1.json" 2>/dev/null || echo '[]' > "${output_dir}/posts_q1.json"
      jq -f /tmp/xab_parse.jq "${output_dir}/brave_q2.json" > "${output_dir}/posts_q2.json" 2>/dev/null || echo '[]' > "${output_dir}/posts_q2.json"

      # Merge: prioritize x_post > x_profile > news, dedupe, cap at max
      cat > /tmp/xab_merge.jq << 'JQEOF'
      ($max | tonumber) as $limit |
      flatten |
      unique_by(.url) |
      . as $all |
      [
        ($all[] | select(.source == "x_post")),
        ($all[] | select(.source == "x_profile")),
        ($all[] | select(.source == "news"))
      ] |
      unique_by(.url) |
      .[0:$limit]
      JQEOF

      jq -s --arg max "${max_tweets}" -f /tmp/xab_merge.jq "${output_dir}/posts_q1.json" "${output_dir}/posts_q2.json" > "${output_dir}/tweets.json"
      cat "${output_dir}/tweets.json"

  - id: format-tweets
    command: |
      cat > /tmp/xab_format.jq << 'JQEOF'
      {
        count: length,
        x_post_count: [.[] | select(.source == "x_post")] | length,
        x_profile_count: [.[] | select(.source == "x_profile")] | length,
        news_count: [.[] | select(.source == "news")] | length,
        posts: [.[] | {
          author: .author,
          content: (.content | gsub("\\n"; " ") | .[0:500]),
          title: (.title | .[0:200]),
          url: .url,
          date: .date,
          source: .source
        }],
        authors: ([.[].author] | unique),
        text_block: ([.[] | "- \(.author) (\(.source)): \(.content | gsub("\\n"; " ") | .[0:300])"] | join("\n"))
      }
      JQEOF

      jq -c -f /tmp/xab_format.jq "${output_dir}/tweets.json" > "${output_dir}/formatted.json"
      cat "${output_dir}/formatted.json"

  - id: generate-script
    stdin: $format-tweets.stdout
    prompt: |
      Create a 5-minute conversational audio briefing about "${topic}" based on
      the X/Twitter posts and related discussions below.

      Guidelines:
      - Write for text-to-speech: no URLs, hashtags, or @ symbols in the script
      - Use natural spoken language with conversational transitions
      - Start with a greeting, mention the topic
      - Group by theme, not chronologically
      - Attribute quotes and insights to specific people by name
      - End with overall sentiment summary and key takeaways
      - Target approximately 700 words for 5 minutes
    system: >
      You are a tech podcast host creating an engaging audio briefing.
      Write scripts that sound natural when read aloud. No bullet points,
      no headers, no visual formatting. Use spoken transitions like
      "Now let's talk about..." and "What's interesting is..."

  - id: save-script
    stdin: $generate-script.stdout
    command: |
      cat > "${output_dir}/script.txt"
      wc_words=$(wc -w < "${output_dir}/script.txt" | tr -d ' ')
      wc_chars=$(wc -c < "${output_dir}/script.txt" | tr -d ' ')
      printf '{"script_file":"%s","word_count":%s,"char_count":%s}' "${output_dir}/script.txt" "$wc_words" "$wc_chars"

  - id: tts
    command: |
      if [ "${skip_tts}" = "true" ]; then
        echo '{"status":"skipped","reason":"skip_tts=true","audio_file":null}'
        exit 0
      fi

      case "${voice}" in
        rachel) voice_id="21m00Tcm4TlvDq8ikWAM" ;;
        adam|*) voice_id="pNInz6obpgDQGcFmaJgB" ;;
      esac

      script_text=$(cat "${output_dir}/script.txt")
      audio_file="${output_dir}/brief.mp3"

      jq -n --arg text "$script_text" '{"text": $text, "model_id": "eleven_multilingual_v2"}' > "${output_dir}/tts_request.json"

      http_code=$(curl -s -w '%{http_code}' \
        -X POST "https://api.elevenlabs.io/v1/text-to-speech/${voice_id}" \
        -H "xi-api-key: ${ELEVENLABS_API_KEY}" \
        -H "Content-Type: application/json" \
        -d @"${output_dir}/tts_request.json" \
        -o "$audio_file")

      if [ "$http_code" -ge 200 ] && [ "$http_code" -lt 300 ] && [ -s "$audio_file" ]; then
        size=$(stat -c%s "$audio_file" 2>/dev/null || stat -f%z "$audio_file" 2>/dev/null || echo 0)
        printf '{"status":"ok","audio_file":"%s","size_bytes":%s,"voice":"%s","voice_id":"%s"}' "$audio_file" "$size" "${voice}" "$voice_id"
      else
        printf '{"status":"error","http_code":%s,"audio_file":null}' "$http_code"
        exit 1
      fi

  - id: report
    command: |
      cat > /tmp/xab_report.jq << 'JQEOF'
      {
        topic: $topic,
        total_posts: .count,
        x_posts: .x_post_count,
        x_profiles: .x_profile_count,
        news_mentions: .news_count,
        unique_sources: (.authors | length),
        sources: .authors,
        script_preview: ($script | .[0:300]),
        tts_skipped: ($skip == "true"),
        summary: (
          "X Audio Brief: " + $topic + "\n" +
          "Found " + (.count | tostring) + " items (" +
          (.x_post_count | tostring) + " X posts, " +
          (.x_profile_count | tostring) + " X profiles, " +
          (.news_count | tostring) + " news) from " +
          (.authors | length | tostring) + " sources.\n" +
          if $skip == "true" then "TTS skipped (skip_tts=true)"
          else "Audio generated" end
        )
      }
      JQEOF

      script_text=$(cat "${output_dir}/script.txt" 2>/dev/null || echo "")
      jq --arg topic "${topic}" --arg skip "${skip_tts}" --arg script "$script_text" -f /tmp/xab_report.jq "${output_dir}/formatted.json"
