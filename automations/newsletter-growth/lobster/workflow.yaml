# Lobster workflow: newsletter-growth
# Collects data for newsletter cross-promotion analysis and churn tracking
#
# Usage:
#   lobster run --file workflow.yaml --args-json '{"your_newsletter":"My Newsletter","your_niche":"AI agents","subscriber_count":"5000"}'
#
# This workflow collects data and uses llm_task.invoke for candidate evaluation
# and churn analysis.
#
# Requires: jq, curl

name: newsletter-growth
description: Find cross-promotion opportunities, collect newsletter data, track churn patterns

args:
  your_newsletter:
    description: "Your newsletter name"
  your_niche:
    description: "Your niche/topic area"
  subscriber_count:
    description: "Your subscriber count"
  unsubscribe_csv:
    description: "Path to unsubscribe CSV (date,email,reason) â€” optional"
    default: ""
  state_file:
    description: "Path to state file for tracking seen newsletters"
    default: "/tmp/clawflows-newsletter-growth-state.json"

steps:
  - id: load-state
    command: cat "${state_file}" 2>/dev/null || echo '{"seen_newsletters":[],"proposals_sent":[]}'

  - id: search-newsletters
    command: |
      # Search for newsletters in the niche using web search patterns
      # We fetch from multiple sources to find potential swap partners
      tmpf=$(mktemp)
      echo '[]' > "$tmpf"

      # Search Substack discover
      curl -sf "https://substack.com/api/v1/search?query=$(echo "${your_niche}" | tr ' ' '+')+newsletter&type=publication&page=0&limit=10" \
        | jq -c '[.results[]? | {name: .name, url: .url, description: (.description // ""), subscriber_count: (.subscriberCount // null), platform: "substack"}]' \
        > /tmp/lb_nl_sub.json 2>/dev/null || echo '[]' > /tmp/lb_nl_sub.json

      jq -sc '.[0] + .[1]' "$tmpf" /tmp/lb_nl_sub.json > /tmp/lb_nl_merged.json
      mv /tmp/lb_nl_merged.json "$tmpf"

      cat "$tmpf"
      rm -f "$tmpf" /tmp/lb_nl_sub.json

  - id: collect-newsletter-data
    stdin: $search-newsletters.stdout
    command: |
      cat > /tmp/lb_nl_found.json
      # Enrich with our metadata for analysis
      jq -c --arg our_name "${your_newsletter}" --arg our_niche "${your_niche}" --arg our_subs "${subscriber_count}" '
        {
          our_newsletter: $our_name,
          our_niche: $our_niche,
          our_subscribers: ($our_subs | tonumber),
          candidates: .,
          candidate_count: length,
          analysis_needed: "LLM should evaluate each candidate for swap potential (HIGH/MEDIUM/LOW)"
        }
      ' /tmp/lb_nl_found.json
      rm -f /tmp/lb_nl_found.json

  - id: analyze-churn
    command: |
      csv="${unsubscribe_csv}"
      if [ -z "$csv" ] || [ ! -f "$csv" ]; then
        echo '{"churn_analysis": "no_data", "message": "No unsubscribe CSV provided"}'
        exit 0
      fi
      # Parse CSV and compute basic churn stats
      # Expected format: date,email,reason (with header)
      tmpf=$(mktemp)
      tail -n +2 "$csv" | awk -F',' '
        { dates[$1]++; reasons[$3]++; total++ }
        END {
          printf "{\"total_unsubscribes\":%d,\"by_date\":{", total
          first=1; for (d in dates) { if(!first) printf ","; printf "\"%s\":%d", d, dates[d]; first=0 }
          printf "},\"by_reason\":{"
          first=1; for (r in reasons) { if(!first) printf ","; printf "\"%s\":%d", r, reasons[r]; first=0 }
          printf "}}"
        }
      ' > "$tmpf"
      cat "$tmpf"
      rm -f "$tmpf"

  - id: save-state
    stdin: $collect-newsletter-data.stdout
    command: |
      cat > /tmp/lb_nl_data.json
      # Update state with newly seen newsletters
      prev=$(cat "${state_file}" 2>/dev/null || echo '{"seen_newsletters":[],"proposals_sent":[]}')
      new_names=$(jq -r '.candidates[]?.name // empty' /tmp/lb_nl_data.json 2>/dev/null)
      echo "$prev" | jq --arg date "$(date -u +%Y-%m-%d)" --argjson data "$(cat /tmp/lb_nl_data.json)" '
        .last_run = $date |
        .seen_newsletters = (.seen_newsletters + [$data.candidates[]?.name // empty] | unique)
      ' > "${state_file}"
      cat /tmp/lb_nl_data.json
      rm -f /tmp/lb_nl_data.json

  - id: llm_evaluate
    stdin: $save-state.stdout
    command: |
      cat > /tmp/nl_llm_input.json
      DATA=$(cat /tmp/nl_llm_input.json)
      llm_task.invoke <<PROMPT
      You are a newsletter growth strategist. Evaluate these potential cross-promotion partners for "${your_newsletter}" (${subscriber_count} subscribers, niche: ${your_niche}):

      $DATA

      For each candidate, rate swap potential (HIGH/MEDIUM/LOW) based on:
      - Audience overlap and complementarity
      - Subscriber count similarity (Â±50% is ideal)
      - Niche alignment

      Also generate a personalized outreach pitch for the top 3.

      Return JSON: { "evaluations": [{ "name": "...", "rating": "HIGH|MEDIUM|LOW", "reasoning": "...", "outreach_pitch": "..." }] }
      PROMPT
      rm -f /tmp/nl_llm_input.json
    env:
      CLAWD_URL: "http://localhost:1691"

  - id: llm_churn
    stdin: $analyze-churn.stdout
    command: |
      cat > /tmp/nl_churn_input.json
      CHURN=$(cat /tmp/nl_churn_input.json)
      if echo "$CHURN" | jq -e '.churn_analysis == "no_data"' >/dev/null 2>&1; then
        echo '{"churn_insights": "no_data"}'
      else
        llm_task.invoke <<PROMPT
      Analyze these newsletter churn patterns:

      $CHURN

      Identify: peak churn periods, top reasons, and 3 actionable recommendations to reduce churn.
      Return JSON: { "peak_periods": [...], "top_reasons": [...], "recommendations": [...] }
      PROMPT
      fi
      rm -f /tmp/nl_churn_input.json
    env:
      CLAWD_URL: "http://localhost:1691"

  - id: report
    stdin: $save-state.stdout
    command: |
      cat > /tmp/lb_nl_report.json
      EVALS=$(cat <<'EVALEOF'
      $llm_evaluate.stdout
      EVALEOF
      )
      CHURN_INSIGHTS=$(cat <<'CHURNEOF'
      $llm_churn.stdout
      CHURNEOF
      )
      echo "$EVALS" > /tmp/lb_nl_evals.json
      echo "$CHURN_INSIGHTS" > /tmp/lb_nl_churn.json
      jq -r --argjson evals "$(cat /tmp/lb_nl_evals.json 2>/dev/null || echo '{"evaluations":[]}')" --argjson churn "$(cat /tmp/lb_nl_churn.json 2>/dev/null || echo '{"churn_insights":"no_data"}')" '
        "ğŸ“° Newsletter Growth Report\n" +
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n" +
        "Newsletter: \(.our_newsletter) (\(.our_subscribers) subs)\n" +
        "Niche: \(.our_niche)\n\n" +
        "ğŸ” Found \(.candidate_count) potential swap partners:\n" +
        (if ($evals.evaluations // []) | length > 0 then
          ($evals.evaluations | map(
            "  â€¢ \(.name) [\(.rating)] â€” \(.reasoning)" +
            if .outreach_pitch then "\n    ğŸ“ Pitch: \(.outreach_pitch)" else "" end
          ) | join("\n"))
        else
          (.candidates[:10] | map("  â€¢ \(.name // "unknown") (\(.platform // "unknown"))" + if .subscriber_count then " ~\(.subscriber_count) subs" else "" end) | join("\n"))
        end) +
        "\n\nğŸ“‰ Churn Insights:\n" +
        (if ($churn.churn_insights // "") == "no_data" then
          "  No churn data available."
        else
          "  Peak periods: " + (($churn.peak_periods // []) | join(", ")) + "\n" +
          "  Top reasons: " + (($churn.top_reasons // []) | join(", ")) + "\n" +
          "  Recommendations:\n" + (($churn.recommendations // []) | map("    â†’ \(.)") | join("\n"))
        end)
      ' /tmp/lb_nl_report.json
      rm -f /tmp/lb_nl_report.json /tmp/lb_nl_evals.json /tmp/lb_nl_churn.json
